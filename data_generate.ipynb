{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2a996c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import pickle\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf273bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "synthetic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"synthetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4464e66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/split_documents.pkl\", \"rb\") as f:\n",
    "    split_documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfd81fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "effe6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-5-nano\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticData(BaseModel):\n",
    "    \"\"\"Synthetic data with details.\"\"\"\n",
    "    query: str = Field(..., description=\"The query of the data\")\n",
    "    answers: str = Field(..., description=\"The answers of the data\")\n",
    "    page_number: str = Field(..., description=\"The page number of the evidence\")\n",
    "    evidence: str = Field(..., description=\"The evidence of the data\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0d0d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = split_documents[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bb7677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 109)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trimmed), len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "55bf2267",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a careful dataset generator for RAG. Only answer from the provided passage.\"\n",
    "    \n",
    "user_prompt = f\"\"\"\n",
    "            Task: Extract 3 atomic facts and write 1 QA whose answer from following document \n",
    "            Response: query : question, answers : answer, evidence : page content for the answer\n",
    "        \"\"\"\n",
    "\n",
    "queries = []\n",
    "for doc in trimmed:\n",
    "    prompt = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"page number: \" + str(doc.metadata[\"page\"])},\n",
    "        {\"role\": \"user\", \"content\": \"content : \" + doc.page_content},\n",
    "    ]\n",
    "    queries.append(prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7771daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_structure = llm.with_structured_output(SyntheticData)\n",
    "responses = model_with_structure.batch(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b855b9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0d09e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for r in responses:\n",
    "    obj = {\n",
    "        \"query\": r.query,\n",
    "        \"answers\": r.answers,\n",
    "        \"evidence\": r.evidence,\n",
    "        \"page_number\": r.page_number,\n",
    "    }\n",
    "    arr.append(obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c7fd401",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/synthetic_out.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for r in arr:\n",
    "        f.write(json.dumps(r, ensure_ascii=False, indent=2) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(arr)\n",
    "df.to_csv(\"outputs/synthetic_out.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb26831e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What should central banks do to manage price stability according to the document?\n",
      "Answers: 1) Central banks should remain vigilant and react promptly to shifts in the balance of risks to price stability. 2) Provided inflation expectations remain well anchored, policy interest rate reductions should continue in economies in which underlying inflation is projected to moderate towards target. 3) Maintaining central bank independence will preserve policy credibility and reduce the volatility and persistence of inflation.\n"
     ]
    }
   ],
   "source": [
    "# To get 'query' and 'answers' in a specific row (e.g., row number i), use:\n",
    "i = 15  # Change this to your desired row index\n",
    "query = df.loc[i, \"query\"]\n",
    "answers = df.loc[i, \"answers\"]\n",
    "print(\"Query:\", query)\n",
    "print(\"Answers:\", answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c55c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
