{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1454872b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5f96a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i + 1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8aebf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-17 17:28:10--  https://raw.githubusercontent.com/teddylee777/langchain-kr/refs/heads/main/10-Retriever/data/ai-story.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16574 (16K) [text/plain]\n",
      "Saving to: ‘cohere-sample.txt’\n",
      "\n",
      "cohere-sample.txt   100%[===================>]  16.19K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2025-11-17 17:28:10 (7.50 MB/s) - ‘cohere-sample.txt’ saved [16574/16574]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/teddylee777/langchain-kr/refs/heads/main/10-Retriever/data/ai-story.txt -O cohere-sample.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aedcfe4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_cohere'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ContextualCompressionRetriever\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CohereEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatCohere\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_cohere\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CohereRerank, CohereRagRetriever\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_cohere'"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_cohere import CohereRerank, CohereRagRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import os\n",
    "\n",
    "user_query = \"what is Cohere Toolkit?\"\n",
    "\n",
    "# Define the Cohere LLM\n",
    "llm = ChatCohere(\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"], model=\"command-a-03-2025\"\n",
    ")\n",
    "\n",
    "# Define the Cohere embedding model\n",
    "embeddings = CohereEmbeddings(\n",
    "    cohere_api_key=os.environ[\"COHERE_API_KEY\"], model=\"embed-english-light-v3.0\"\n",
    ")\n",
    "\n",
    "# Load text files and split into chunks, you can also use data gathered elsewhere in your application\n",
    "raw_documents = WebBaseLoader(\n",
    "    \"https://docs.cohere.com/docs/cohere-toolkit\"\n",
    ").load()\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "# Create a vector store from the documents\n",
    "db = Chroma.from_documents(documents, embeddings)\n",
    "\n",
    "# Create Cohere's reranker with the vector DB using Cohere's embeddings as the base retriever\n",
    "reranker = CohereRerank(\n",
    "    cohere_api_key=\"COHERE_API_KEY\", model=\"rerank-english-v3.0\"\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=reranker, base_retriever=db.as_retriever()\n",
    ")\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    user_query\n",
    ")\n",
    "# Print the relevant documents from using the embeddings and reranker\n",
    "print(compressed_docs)\n",
    "\n",
    "# Create the cohere rag retriever using the chat model\n",
    "rag = CohereRagRetriever(llm=llm, connectors=[])\n",
    "docs = rag.get_relevant_documents(\n",
    "    user_query,\n",
    "    documents=compressed_docs,\n",
    ")\n",
    "# Print the documents\n",
    "print(\"Documents:\")\n",
    "for doc in docs[:-1]:\n",
    "    print(doc.metadata)\n",
    "    print(\"\\n\\n\" + doc.page_content)\n",
    "    print(\"\\n\\n\" + \"-\" * 30 + \"\\n\\n\")\n",
    "# Print the final generation\n",
    "answer = docs[-1].page_content\n",
    "print(\"Answer:\")\n",
    "print(answer)\n",
    "# Print the final citations\n",
    "citations = docs[-1].metadata[\"citations\"]\n",
    "print(\"Citations:\")\n",
    "print(citations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b84244",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.postprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostprocessor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcohere_rerank\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CohereRerank\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweb\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     SimpleWebPageReader,\n\u001b[1;32m      4\u001b[0m )  \u001b[38;5;66;03m# first, run `pip install llama-index-readers-web`\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create index (we are using an example page from Cohere's docs)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.postprocessor'"
     ]
    }
   ],
   "source": [
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.readers.web import (\n",
    "    SimpleWebPageReader,\n",
    ")  # first, run `pip install llama-index-readers-web`\n",
    "\n",
    "# create index (we are using an example page from Cohere's docs)\n",
    "documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "    [\"https://docs.cohere.com/v2/docs/cohere-embed\"]\n",
    ")  # you can replace this with any other reader or documents\n",
    "index = VectorStoreIndex.from_documents(documents=documents)\n",
    "\n",
    "# create reranker\n",
    "cohere_rerank = CohereRerank(\n",
    "    api_key=\"COHERE_API_KEY\", model=\"rerank-english-v3.0\", top_n=2\n",
    ")\n",
    "\n",
    "# query the index\n",
    "query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,\n",
    "    node_postprocessors=[cohere_rerank],\n",
    ")\n",
    "\n",
    "print(query_engine)\n",
    "\n",
    "# generate a response\n",
    "response = query_engine.query(\n",
    "    \"What is Cohere's Embed Model?\",\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "# To view the source documents\n",
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "\n",
    "pprint_response(response, show_source=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a5fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
